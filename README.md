# üß† Comparativo de Modelos de Machine Learning (Iris Dataset)

Este projeto consiste na implementa√ß√£o e compara√ß√£o de tr√™s algoritmos cl√°ssicos de Aprendizado de M√°quina Supervisionado para a classifica√ß√£o do dataset **Iris**. O objetivo √© treinar, testar e analisar o desempenho de cada modelo.

## üìÇ Estrutura do Projeto

O projeto foi dividido em notebooks separados para isolar o treinamento de cada modelo:

1.  **`1_SVM.ipynb`**: Implementa√ß√£o do Support Vector Machine (Kernel Linear).
2.  **`2_RandomForest.ipynb`**: Implementa√ß√£o do Random Forest (Ensemble).
3.  **`3_KNN.ipynb`**: Implementa√ß√£o do K-Nearest Neighbors (Baseado em dist√¢ncia).

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3
* **Ambiente:** Jupyter Notebook (VS Code)
* **Bibliotecas:**
    * `pandas`: Manipula√ß√£o de dados.
    * `scikit-learn`: Algoritmos de Machine Learning e m√©tricas.
    * `seaborn` & `matplotlib`: Visualiza√ß√£o de dados (Matriz de Confus√£o).

## üöÄ Como Executar

Certifique-se de ter as depend√™ncias instaladas:


pip install pandas seaborn matplotlib scikit-learn notebook

## üìö Fun√ß√µes e Conceitos Utilizados

Abaixo, detalho as principais fun√ß√µes e m√©todos do `scikit-learn` aplicados no projeto para garantir a reprodutibilidade e efic√°cia dos testes:

### 1. Pr√©-processamento de Dados
* **`load_iris()`**: Fun√ß√£o utilit√°ria que carrega o dataset Iris diretamente da biblioteca, contendo 150 amostras de 3 esp√©cies de flores.
* **`train_test_split(test_size=0.3, random_state=42)`**:
    * Divide o conjunto de dados em duas partes: **70% para Treino** (aprender padr√µes) e **30% para Teste** (validar conhecimento).
    * O par√¢metro `random_state=42` foi essencial para fixar a "semente" aleat√≥ria, garantindo que a divis√£o seja sempre a mesma em todas as execu√ß√µes e tornando a compara√ß√£o entre os modelos justa.

### 2. Modelos de Machine Learning (Instancia√ß√£o)
Cada modelo foi configurado com hiperpar√¢metros espec√≠ficos para o cen√°rio:
* **`SVC(kernel='linear')`**: Instancia o Support Vector Machine configurado para buscar uma linha reta (hiperplano) que melhor separa as classes.
* **`RandomForestClassifier(n_estimators=100)`**: Instancia o modelo criando uma "floresta" composta por 100 √°rvores de decis√£o que votam na classifica√ß√£o final.
* **`KNeighborsClassifier(n_neighbors=5)`**: Instancia o algoritmo KNN configurado para observar os 5 vizinhos mais pr√≥ximos antes de decidir a classe da flor.

### 3. Ciclo de Vida do Modelo
* **`.fit(X_train, y_train)`**: O m√©todo de **Treinamento**. √â aqui que o algoritmo recebe os dados de estudo e ajusta seus par√¢metros internos (aprende).
* **`.predict(X_test)`**: O m√©todo de **Infer√™ncia**. O modelo recebe dados novos (que nunca viu) e tenta classificar com base no que aprendeu.

### 4. Avalia√ß√£o e M√©tricas
* **`accuracy_score()`**: Calcula a porcentagem global de acertos (ex: 0.97 significa 97% de precis√£o).
* **`confusion_matrix()`**: Gera uma matriz que cruza as classes reais vs. as classes preditas, permitindo ver exatamente onde o modelo errou.
* **`sns.heatmap()`**: Fun√ß√£o da biblioteca Seaborn utilizada para transformar a matriz de confus√£o num√©rica em um mapa de calor visual, facilitando a interpreta√ß√£o dos erros.

```bash
